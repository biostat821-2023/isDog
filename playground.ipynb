{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "32/32 [==============================] - 103s 3s/step - loss: -9332477.0000 - accuracy: 0.0100 - val_loss: -73307784.0000 - val_accuracy: 0.0050\n",
      "Epoch 2/10\n",
      "32/32 [==============================] - 51s 2s/step - loss: -1252032384.0000 - accuracy: 0.0100 - val_loss: -5156636672.0000 - val_accuracy: 0.0050\n",
      "Epoch 3/10\n",
      "32/32 [==============================] - 62s 2s/step - loss: -24603400192.0000 - accuracy: 0.0100 - val_loss: -71922573312.0000 - val_accuracy: 0.0050\n",
      "Epoch 4/10\n",
      "32/32 [==============================] - 60s 2s/step - loss: -212227768320.0000 - accuracy: 0.0100 - val_loss: -474883194880.0000 - val_accuracy: 0.0050\n",
      "Epoch 5/10\n",
      "32/32 [==============================] - 59s 2s/step - loss: -1036646088704.0000 - accuracy: 0.0100 - val_loss: -1986637856768.0000 - val_accuracy: 0.0050\n",
      "Epoch 6/10\n",
      "32/32 [==============================] - 60s 2s/step - loss: -3685091377152.0000 - accuracy: 0.0100 - val_loss: -6295967498240.0000 - val_accuracy: 0.0050\n",
      "Epoch 7/10\n",
      "32/32 [==============================] - 53s 2s/step - loss: -10383272181760.0000 - accuracy: 0.0100 - val_loss: -16433076502528.0000 - val_accuracy: 0.0050\n",
      "Epoch 8/10\n",
      "32/32 [==============================] - 46s 1s/step - loss: -24970574954496.0000 - accuracy: 0.0100 - val_loss: -37118105616384.0000 - val_accuracy: 0.0050\n",
      "Epoch 9/10\n",
      "32/32 [==============================] - 46s 1s/step - loss: -53108247887872.0000 - accuracy: 0.0100 - val_loss: -75223911104512.0000 - val_accuracy: 0.0050\n",
      "Epoch 10/10\n",
      "32/32 [==============================] - 58s 2s/step - loss: -103028698906624.0000 - accuracy: 0.0100 - val_loss: -140460488130560.0000 - val_accuracy: 0.0050\n",
      "  7/268 [..............................] - ETA: 2:26 - loss: -132179690520576.0000 - accuracy: 0.0250WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 268 batches). You may need to use the repeat() function when building your dataset.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 268 batches). You may need to use the repeat() function when building your dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268/268 [==============================] - 8s 26ms/step - loss: -132179690520576.0000 - accuracy: 0.0250\n",
      "Test accuracy: 0.02500000037252903\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset and split into training and validation sets\n",
    "(train_ds, val_ds), info = tfds.load(\n",
    "    \"stanford_dogs\",\n",
    "    split=[\"train[:80%]\", \"train[80%:]\"],\n",
    "    with_info=True,\n",
    "    as_supervised=True,\n",
    ")\n",
    "\n",
    "# Select a subset of the dataset\n",
    "train_ds = train_ds.take(1000)\n",
    "val_ds = val_ds.take(200)\n",
    "\n",
    "\n",
    "# Preprocess the data\n",
    "def preprocess_image(image, label):\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    image = tf.image.resize(image, (224, 224))\n",
    "    image = image / 255.0\n",
    "    return image, label\n",
    "\n",
    "\n",
    "train_ds = train_ds.map(preprocess_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "val_ds = val_ds.map(preprocess_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\n",
    "# Specify the batch size\n",
    "batch_size = 32\n",
    "\n",
    "# Shuffle and batch the data\n",
    "train_ds = (\n",
    "    train_ds.cache()\n",
    "    .shuffle(1000)\n",
    "    .batch(batch_size)\n",
    "    .prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    ")\n",
    "val_ds = val_ds.cache().batch(batch_size).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "\n",
    "# Build the model\n",
    "model = tf.keras.models.Sequential(\n",
    "    [\n",
    "        tf.keras.layers.Conv2D(\n",
    "            32, (3, 3), activation=\"relu\", input_shape=(224, 224, 3)\n",
    "        ),\n",
    "        tf.keras.layers.MaxPooling2D(2, 2),\n",
    "        tf.keras.layers.Conv2D(64, (3, 3), activation=\"relu\"),\n",
    "        tf.keras.layers.MaxPooling2D(2, 2),\n",
    "        tf.keras.layers.Conv2D(128, (3, 3), activation=\"relu\"),\n",
    "        tf.keras.layers.MaxPooling2D(2, 2),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(128, activation=\"relu\"),\n",
    "        tf.keras.layers.Dense(1, activation=\"sigmoid\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    loss=\"binary_crossentropy\",\n",
    "    optimizer=tf.keras.optimizers.Adam(lr=0.001),\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "epochs = 10\n",
    "history = model.fit(train_ds, epochs=epochs, validation_data=val_ds)\n",
    "\n",
    "# Evaluate the model\n",
    "test_ds, info = tfds.load(\n",
    "    \"stanford_dogs\", split=\"test\", with_info=True, as_supervised=True\n",
    ")\n",
    "test_ds = test_ds.take(200)\n",
    "test_ds = test_ds.map(preprocess_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "test_ds = test_ds.batch(batch_size)\n",
    "test_loss, test_acc = model.evaluate(\n",
    "    test_ds, steps=info.splits[\"test\"].num_examples // batch_size\n",
    ")\n",
    "print(\"Test accuracy:\", test_acc)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
